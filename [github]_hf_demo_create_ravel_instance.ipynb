{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUyOIsvigY7N"
   },
   "source": [
    "# Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flbgMtAlcLn1"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zLdMswKcLn1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REPO_DIR = f'/share/u/can/ravel'\n",
    "SRC_DIR = os.path.join(REPO_DIR, 'src')\n",
    "MODEL_DIR = os.path.join(REPO_DIR, 'models')\n",
    "DATA_DIR = os.path.join(REPO_DIR, 'data')\n",
    "\n",
    "for d in [MODEL_DIR, DATA_DIR]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(REPO_DIR)\n",
    "sys.path.append(SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnHoWtKGgqP9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import accelerate\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15GeWK3MPDKz"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baKMuwvv0QvH"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "98dab42366f6487e812d64c3f4caf891",
      "e7ee55ad866d47fbbaecd8404031514a",
      "8a9cec0ca6bc446e920b0434d285db7f",
      "61a9760d2ffc4d4a8adfa3943d38c45f",
      "735646f58bc0439c8443c999c4197348",
      "c61ad4c389c94859928b9354b5642a85",
      "a5f08ac6fc594248a2849e3f52474b2c",
      "76f85c230aaa4cdda538914ac0dfd2ed",
      "202f3abe8ec549c38dbf47a516b3945c",
      "cbf42146e6464b89ae174ef7384a8282",
      "c7ff0bdf6266424a8740bc02e0251ec8",
      "23b93d91656349678f3bc1471d1c81fe",
      "95354940b8774d9386586148e1af7152",
      "76922547666d449b8bad8654b5fdd1e4",
      "d0813f3a3d8e47f08b82f8da25ed22b3",
      "6ef3717cc254493d8914950d0279b43a",
      "a048c0e793c14a7ca16702ddb16f1f66",
      "f622a017c6dd444d8e0cc7b8dc577b07",
      "336c65f3910b477792c00208744cb018",
      "6b9da8a3028549718c51fdd8e2f5edc8",
      "3b583277acad4b57a80f09ca7afded1d",
      "72b68b5e374c46de976616c9a82351a6",
      "19d9305f5a7b41bba8c4cbe29d9f82f4",
      "16fbe96234b5489288f5c790480f258e",
      "c49ffa4d14e84df7ac33c5191aea3f63",
      "4bbaa0236dba4bbab105cf4a5d808b86",
      "4e424a318cad47ac94104d2dd863792f",
      "31a37e35473a47c0bb5c1161cb75a181",
      "c8e6e4d954fc4f75b169477a5c025bf5",
      "20335893ae434ec2bf4ad97f1ac43f07",
      "9efbc5e488454af2a29e8a1f33ce8d8c",
      "280680a52e13446997a80a17c83c6f14",
      "b154157c7e0a482390d79a66b28b856e",
      "d728d373f5274b1d9d928e6d2e8a567d",
      "e6e5f7f3096a4d7fb17914926c45e797",
      "a3897824440c4bccba6057885a257563",
      "574164262a3a4bf0ad047cfebd3c776d",
      "91a7647bcba74adb9651b77218388b27",
      "b268c23153b442df9965599ce2c89b04",
      "6545f0c9e9304dceb0c5f77580eb895c",
      "e41b6b4160ee42829ef0e461a7efd4f7",
      "195ce77a18bd4ccfab1b0cdd7d0bcee8",
      "d353c78a01b54a66a806b3a21677ce82",
      "c92193c50b794b618cd2659b29a960c2",
      "07e7dd52cb6f4c7d93efa9bd99d11642",
      "1f9341680cdf4a708bc45aa2939d9722",
      "b160903971c6426f87b198ec92fa0780",
      "14dc056f34764163b3f6e6b975c0a820",
      "87d1ee31ae364e819e186f6119f1f12f",
      "e6d599d2af034db281f75a02e4b9df07",
      "06cf09eed3ad46ef825487ebc408f789",
      "447290ee525e41029e923203866c3e2b",
      "73e0972003d04fc9a54b3464841f6429",
      "27ad06e58bd64b0184c68454a1d17906",
      "93b9df7fe0984083aa511c29e5b911dd",
      "b58bdbc761e8470bb0ab621e9284ee60",
      "f0c8dbd6c6ad4fe8854bf92184a1cf81",
      "425f43e44a2e4c08af54d3224a6531b1",
      "69bad488e2134ef39ec2dfee535b93c3",
      "afd676c1f7204867b10761dea4e76eff",
      "51ff0b56894b445289329926e6f6e6a7",
      "c68f48e6c2aa484ea83560fc20dccca6",
      "89c8704856f2446b91a0331eba5886ab",
      "bb3b41ec4503462fb37395ac5450b349",
      "204f49c31dcc4017911b122f292b28ea",
      "4d9a267b19ac493797a959004bd06811",
      "e37fab82c4f54416888c2d0341f63663",
      "329e9056f9ec40eb87f79ceedf12ad47",
      "06b5b4dfe7f143098f0d8d8af51da4f3",
      "fc3d002061e2497598eda4cc0bcdf4d1",
      "8562c07bd34d4b9fa3d9c034f5432ce0",
      "425d1829cdbe4900a46b60fc5976cca9",
      "5f702c3ac38b4002bdd9e871e56ddfb7",
      "80655d3657d040ba94c419a4a0c6e55c",
      "bd4f1058665045b6bc0aa21dbe61d575",
      "8096e154e78a4165a4301ccbae3100b6",
      "98cc83467ddf483f99735ee6c58dbdc0"
     ]
    },
    "id": "byXc9_hW6ZLq",
    "outputId": "6aa109a4-717d-46b5-b8d8-c1351e96cd55"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, LlamaForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "model_name = \"tinyllama\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=MODEL_DIR)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_id, low_cpu_mem_usage=True, device_map='auto', cache_dir=MODEL_DIR,\n",
    "    torch_dtype=torch.bfloat16)\n",
    "model = model.eval()\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "VOCAB = sorted(tokenizer.vocab, key=tokenizer.vocab.get)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "nnsight_model = LanguageModel(\n",
    "    model_id, \n",
    "    low_cpu_mem_usage=True, \n",
    "    device_map=device, \n",
    "    cache_dir=MODEL_DIR,\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    dispatch=True,\n",
    ")\n",
    "# nnsight_model = nnsight_model.eval()\n",
    "\n",
    "tracer_kwargs = {'scan': False, 'validate': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/share/u/can/src/hf.txt', 'r') as f:\n",
    "    hf_token = f.read().strip()\n",
    "\n",
    "torch.set_grad_enabled(False) # avoid blowing up mem\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "model = LanguageModel(\n",
    "    \"google/gemma-2-2b\",\n",
    "    device_map=device,\n",
    "    cache_dir=\"/share/u/can/sae_eval/ravel/models/gemma-2-2b\",\n",
    "    use_auth_token=hf_token,\n",
    "    dispatch=True,\n",
    ")\n",
    "\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\n",
    "    \"google/gemma-2-2b\",\n",
    "    cache_dir=\"/share/u/can/sae_eval/ravel/models/gemma-2-2b\",\n",
    "    use_auth_token=hf_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7H31GM_-iGa"
   },
   "source": [
    "# Create a RAVEL Instance for TinyLLaMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYzs13fAJi1h"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "if not os.path.exists(f'{DATA_DIR}/base.zip'):\n",
    "    hf_hub_download(\n",
    "        repo_id='canrager/ravel',\n",
    "        filename='base.zip',\n",
    "        local_dir=DATA_DIR,\n",
    "    )\n",
    "    os.system(f'unzip {DATA_DIR}/base.zip -d {DATA_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model knowledge of all entity - attribute pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnniGh2I-jYw",
    "outputId": "7fd96496-9a88-43fa-e181-07e5ee21235f"
   },
   "outputs": [],
   "source": [
    "# Generate a dataset of combinations of entities and attribute_specific_prompts\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "entity_type = 'city'\n",
    "\n",
    "attribute_prompts = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{entity_type}_attribute_to_prompts.json')))\n",
    "prompt_splits = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{entity_type}_prompt_to_split.json')))\n",
    "entity_attributes = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{entity_type}_entity_attributes.json')))\n",
    "print(f'#entities={len(entity_attributes)}, #prompt_templates={sum(map(len, attribute_prompts.values()))}')\n",
    "\n",
    "prompts_to_meta_data = {t % x: {'entity': x, 'attr': a, 'template': t}\n",
    "               for x in entity_attributes\n",
    "               for a, ts in attribute_prompts.items()\n",
    "               for t in ts}\n",
    "print(f'total number of prompts{len(prompts_to_meta_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACeQLEvlYevO"
   },
   "outputs": [],
   "source": [
    "# Generate outputs for all prompts (the correct attribute is expected in the output)\n",
    "\n",
    "skip_the_inference_step = True\n",
    "\n",
    "if skip_the_inference_step:\n",
    "    # Can skip the inference step by downloading the pre-computed outputs:\n",
    "    # https://drive.google.com/drive/u/0/folders/1U4Js-NarJa-B_iQc5wr0OXV2G-5BDBsN\n",
    "    pass\n",
    "else: \n",
    "    from utils.generation_utils import generate_batched\n",
    "\n",
    "    prompt_max_length = 48\n",
    "\n",
    "    prompt_to_output = generate_batched(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        list(prompts_to_meta_data),\n",
    "        prompt_max_length+8,\n",
    "        prompt_max_length=prompt_max_length,\n",
    "        batch_size=64)\n",
    "    prompt_to_output = {k: v[len(k):] for k, v in prompt_to_output}\n",
    "\n",
    "    json.dump(prompt_to_output, open(os.path.join('ravel_tinyllama_city_prompt_to_output.json'), 'w'), ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Rix7lyGHwYL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3dIZpkeyOtu",
    "outputId": "921a9d95-f3d2-4ecc-d532-a1aaa151f964"
   },
   "outputs": [],
   "source": [
    "prompt_to_output = json.load(open(os.path.join(DATA_DIR, model_name, 'ravel_tinyllama_city_prompt_to_output.json')))\n",
    "len(prompt_to_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-haNRu475QT4"
   },
   "outputs": [],
   "source": [
    "#@title Behavioral Test\n",
    "\n",
    "## Check whether model output matches the correct attribute\n",
    "# Keep top 400 entities with highest sum of known attributes across all prompts\n",
    "# Keep top 12 templates per attribute\n",
    "\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from zoneinfo import ZoneInfo\n",
    "import datetime\n",
    "\n",
    "def timezone_name_to_utc_offset(name):\n",
    "  offset =  ZoneInfo(name).utcoffset(datetime.datetime.now()).seconds\n",
    "  sign = '+'\n",
    "  if offset // 3600 >= 12:\n",
    "    offset = 24 * 3600 - offset\n",
    "    sign = '-'\n",
    "  fmt_offset = str(datetime.timedelta(seconds=offset)).rsplit(':', 1)[0]\n",
    "  if fmt_offset.startswith('0') and offset >= 1800:\n",
    "    fmt_offset = fmt_offset[1:]\n",
    "  return f'{sign}{fmt_offset}'\n",
    "\n",
    "\n",
    "# TODO: Pull out attribute checking to functions\n",
    "\n",
    "sorted_entity = sorted(set([v['entity'] for v in prompts_to_meta_data.values()]))\n",
    "sorted_template = sorted(set([v['template'] for v in prompts_to_meta_data.values()]))\n",
    "stats = np.zeros([len(sorted_entity), len(sorted_template)])\n",
    "for p, out in prompt_to_output.items():\n",
    "  attr = prompts_to_meta_data[p]['attr']\n",
    "  entity = prompts_to_meta_data[p]['entity']\n",
    "  label = entity_attributes[entity][attr]\n",
    "  if not label:\n",
    "    continue\n",
    "  norm_label = label.lower()\n",
    "  norm_out = out.split('\"')[0].strip(' \"').replace('\\\\/', '/').lower()\n",
    "  if len(norm_label) < len(norm_out):\n",
    "    correct = int(norm_out.startswith(norm_label))\n",
    "  else:\n",
    "    correct = int(norm_label.startswith(norm_out))\n",
    "\n",
    "  # Exceptions\n",
    "  if re.search('coord|\"lat\"|\"long\"|latitude|coordinates|longitude', p):\n",
    "    try:\n",
    "      correct = int((float(norm_label.strip('-−')) - float(re.findall(r'\\d+', norm_out)[0])) <= 2)\n",
    "    except:\n",
    "      correct = 0\n",
    "  if re.search('United States|United Kingdom', label):\n",
    "    norm_label = label.strip().replace('the ', '')\n",
    "    norm_out = out[len(p):].strip().replace('the ', '')\n",
    "    correct = int(norm_out.startswith(norm_label) or norm_out.startswith('England'))\n",
    "  if re.search('South Korea', label):\n",
    "    correct = int(norm_out.startswith('korea') or norm_out.startswith('south korea'))\n",
    "  if re.search('North America', label):\n",
    "    correct = norm_label in norm_out or norm_out == 'na' or norm_out.startswith('america')\n",
    "  if re.search('Mandarin', label):\n",
    "    correct = norm_out in norm_label or norm_out == 'chinese'\n",
    "  if re.search('language', p) and ',' in norm_label:\n",
    "    correct = any(lang in norm_out for lang in norm_label.split(','))\n",
    "  if re.search('UTC', p) and '/' in norm_label:\n",
    "    norm_label = timezone_name_to_utc_offset(label)\n",
    "    correct = norm_out.startswith(norm_label.split(':')[0])\n",
    "    if not correct and re.search(r'[+\\-]0\\d', norm_out):\n",
    "      correct = norm_out.replace('0', '', 1).startswith(norm_label.split(':')[0])\n",
    "    # Summer daylight saving time\n",
    "    if not correct and (\n",
    "        re.search(r'\\-[5-8]', norm_label) and label.startswith('America') or\n",
    "        re.search(r'\\+[0-3]', norm_label) and label.startswith('Europe') or\n",
    "        re.search(r'\\+[0-3]', norm_label) and label.startswith('Africa')):\n",
    "      #print('SUMMER TIME:', norm_label, norm_out)\n",
    "      out_offset_match = re.search(r'[+\\-]?(\\d\\d?):\\d+', norm_out)\n",
    "      label_offset_match = re.search(r'[+\\-]?(\\d\\d?):\\d+', norm_label)\n",
    "      if out_offset_match and label_offset_match:\n",
    "        norm_out_offset = int(out_offset_match.group(1))\n",
    "        norm_label_offset = int(label_offset_match.group(1))\n",
    "        correct = (norm_out_offset <= norm_label_offset + 1 and\n",
    "                   norm_out_offset >= norm_label_offset - 1)\n",
    "    if not correct and re.search(r'[+\\-](\\d+)', norm_out) and int(\n",
    "        re.search(r'[+\\-](\\d+)', norm_out).group(1)) > 11:\n",
    "      offset = 24 - int(re.search(r'[+\\-](\\d+)', norm_out).group(1))\n",
    "      correct = str(offset) in norm_label\n",
    "  stats[sorted_entity.index(prompts_to_meta_data[p]['entity']), sorted_template.index(prompts_to_meta_data[p]['template'])] += int(correct)\n",
    "\n",
    "print('-----------------------------------')\n",
    "for i in np.argsort(stats.sum(axis=0))[::-1]:\n",
    "  print(sorted_template[i], int(stats[:, i].sum()), len(stats[:, i]))\n",
    "for i in np.argsort(stats.sum(axis=-1))[::-1]:\n",
    "  print(sorted_entity[i], int(stats[i].sum()), len(stats[i]))\n",
    "\n",
    "\n",
    "kept_entity_index = np.argsort(stats.sum(axis=1))[-400:]\n",
    "KEPT_ENTITY = [sorted_entity[i] for i in kept_entity_index]\n",
    "topk_template_index = set(np.argsort(stats.sum(axis=0))[-200:])\n",
    "kept_template_index = []\n",
    "# A dict of all kept attribute to prompts.\n",
    "KEPT_ATTR_TO_PROMPT_AND_SPLIT = {}\n",
    "for attr in attribute_prompts:\n",
    "  # Kept the top 4 to 12 templates per attribute.\n",
    "  attr_indices = [sorted_template.index(t) for t in attribute_prompts[attr]]\n",
    "  per_attr_kept_template_index = sorted(attr_indices, key=lambda i: stats[:, i].sum())[-12:][::-1]\n",
    "  per_attr_kept_template_index = [x for i, x in enumerate(per_attr_kept_template_index)\n",
    "                                  if x in topk_template_index or i < 4]\n",
    "  kept_template_index.extend(per_attr_kept_template_index)\n",
    "  KEPT_ATTR_TO_PROMPT_AND_SPLIT[attr] = {sorted_template[i]: prompt_splits[sorted_template[i]]\n",
    "                               for i in per_attr_kept_template_index}\n",
    "print('Kept %d entity, %d prompt template' % (len(kept_entity_index), len(kept_template_index)))\n",
    "\n",
    "print('Average accuracy: %.2f%%' % (100 *  (stats[:, kept_template_index][kept_entity_index, :]).sum()/ (len(kept_entity_index) * len(kept_template_index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkJzIW0cNDSt",
    "outputId": "8aa5c498-6f1a-491c-dfa7-3943e62b03f4"
   },
   "outputs": [],
   "source": [
    "# Print top 12 templates for each attribute\n",
    "\n",
    "attribute_prompts\n",
    "for i in kept_template_index:\n",
    "  print(f'{prompt_splits[sorted_template[i]]}\\t{sorted_template[i]}\\t{stats[:, i][kept_entity_index].mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngPJHQoOLH3b",
    "outputId": "422add7a-bc51-43b0-9bb5-60832c58583f"
   },
   "outputs": [],
   "source": [
    "# train/val/test split of attribute_specific_prompt_templates has been predefined. Check whether the split is roughly balanced.\n",
    "\n",
    "print(sum(map(len, KEPT_ATTR_TO_PROMPT_AND_SPLIT.values())))\n",
    "for attr, prompt_to_split in KEPT_ATTR_TO_PROMPT_AND_SPLIT.items():\n",
    "  print(attr, collections.Counter(prompt_to_split.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoswMLAT8Fk7"
   },
   "source": [
    "### Create an Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "az5kBoagLBDU",
    "outputId": "ea8becbe-157b-4758-e105-ace0995ec28a"
   },
   "outputs": [],
   "source": [
    "# train/val/test split of entities has been predefined. Check whether the split is roughly balanced.\n",
    "import json\n",
    "\n",
    "ENTITY_TYPE = 'city'\n",
    "print(ENTITY_TYPE)\n",
    "ALL_ENTITY_SPLITS = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{ENTITY_TYPE}_entity_to_split.json')))\n",
    "ALL_ATTR_TO_PROMPTS = json.load(open(os.path.join(DATA_DIR, 'base', f'ravel_{ENTITY_TYPE}_attribute_to_prompts.json')))\n",
    "WIKI_PROMPT_SPLITS = json.load(open(os.path.join(DATA_DIR, 'base', f'wikipedia_{ENTITY_TYPE}_entity_prompts.json')))\n",
    "\n",
    "# Filtered\n",
    "KEPT_ENTITY_SPLITS = {e: ALL_ENTITY_SPLITS[e] for e in KEPT_ENTITY} # kept entities to split\n",
    "KEPT_PROMPT_SPLITS = {k: (a, v) for a, d in KEPT_ATTR_TO_PROMPT_AND_SPLIT.items() for k, v in d.items() if k.count('%') == 1}\n",
    "for prompt in WIKI_PROMPT_SPLITS:\n",
    "  KEPT_PROMPT_SPLITS[prompt] = ('Other', WIKI_PROMPT_SPLITS[prompt]['split'])\n",
    "KEPT_ATTR_TO_PROMPT_AND_SPLIT = {k: {p: v for p, v in d.items() if p.count('%') == 1} for k, d in KEPT_ATTR_TO_PROMPT_AND_SPLIT.items()}\n",
    "print(f'Total #entities={len(ALL_ENTITY_SPLITS)} #attributes={len(KEPT_ATTR_TO_PROMPT_AND_SPLIT)} #prompts={sum(map(len, ALL_ATTR_TO_PROMPTS.values()))} #wiki_prompts={len(WIKI_PROMPT_SPLITS)}')\n",
    "print(f'Kept #entities={len(KEPT_ENTITY_SPLITS)} #prompts={len(KEPT_PROMPT_SPLITS)}')\n",
    "for split in ('train', 'val', 'test'):\n",
    "  print(split, f'Kept #entities={len([k for k, v in KEPT_ENTITY_SPLITS.items() if v == split])}',\n",
    "               f'#prompts={len([k for k, v in KEPT_PROMPT_SPLITS.items() if v[1] == split])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEPT_PROMPT_SPLITS.keys()\n",
    "KEPT_PROMPT_SPLITS['city: %s, country:']\n",
    "# prompt: (attr, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuDFPXkjNy-j",
    "outputId": "ab035725-a893-4e14-fda7-9516ba099a85"
   },
   "outputs": [],
   "source": [
    "from utils.generation_utils import generate_batched\n",
    "\n",
    "wiki_prompts = [(t % e) for t, s_e in WIKI_PROMPT_SPLITS.items()\n",
    "                 for e in ([s_e['entity']] if s_e['entity']\n",
    "                           else [a for a in KEPT_ENTITY_SPLITS if KEPT_ENTITY_SPLITS[a] == 'train' or s_e['split'] == 'train'])\n",
    "                 ]\n",
    "print(len(wiki_prompts))\n",
    "\n",
    "wiki_prompt_and_output = generate_batched(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    wiki_prompts,\n",
    "    max_new_tokens=8,\n",
    "    batch_size=64)\n",
    "wiki_prompt_to_output = {k: v[len(k):] for k, v in wiki_prompt_and_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8ZHekPHN6sB",
    "outputId": "5094bf7e-a1f5-4c1c-925f-f3ee42ba3cff"
   },
   "outputs": [],
   "source": [
    "ALL_PROMPT_TO_OUTPUT = {**prompt_to_output, **wiki_prompt_to_output}\n",
    "\n",
    "print(len(ALL_PROMPT_TO_OUTPUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0u90Zo6Gu_W"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "# from utils.intervention_utils import extract_label\n",
    "from utils.generate_ravel_instance import RAVELMetadata\n",
    "\n",
    "# def extract_label(string):\n",
    "#     delimiters = r\"[ \\-\\t,.\\n]\"\n",
    "#     return re.split(delimiters, string.strip())[0]\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_label(text):\n",
    "    tokens = re.split(r'([\"]|[.,;]\\s|\\n| \\(|\\sand)', text + ' ')\n",
    "    x = tokens[0]\n",
    "    digit_match = re.search(r'\\.\\d\\d', x)\n",
    "    if digit_match:\n",
    "        x = x[:digit_match.span(0)[1]]\n",
    "    gender_match = re.match(r'\\s?(his|her|himself|herself|she|he)[^\\w]', x)\n",
    "    if gender_match:\n",
    "        x = x[:gender_match.span(1)[1]]\n",
    "    if not x.strip():\n",
    "        x = ' '.join(text.split(' ')[:2]).rstrip('.,\"\\n')\n",
    "    assert x.strip()\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_first_token(x):\n",
    "  return re.split(r'[^\\w\\+\\-]', x.strip(), re.UNICODE)[0]\n",
    "\n",
    "\n",
    "def filter_inv_example(base_output, inv_output):\n",
    "  different_outputs = (get_first_token(base_output) !=\n",
    "                       get_first_token(inv_output))\n",
    "  valid_outputs = (\n",
    "      re.fullmatch(r'\\s?[a-z0-9.:\\-+]+', extract_label(base_output), re.IGNORECASE) and\n",
    "      re.fullmatch(r'\\s?[a-z0-9.:\\-+]+', extract_label(inv_output), re.IGNORECASE))\n",
    "  return valid_outputs and different_outputs\n",
    "\n",
    "\n",
    "FEATURE_TYPES = datasets.Features({\"input\": datasets.Value(\"string\"), \"label\": datasets.Value(\"string\"),\n",
    "                              \"source_input\": datasets.Value(\"string\"), \"source_label\": datasets.Value(\"string\"),\n",
    "                              \"inv_label\": datasets.Value(\"string\"),\n",
    "                              'split': datasets.Value(\"string\"), 'source_split': datasets.Value(\"string\"),\n",
    "                              'entity': datasets.Value(\"string\"), 'source_entity': datasets.Value(\"string\")})\n",
    "\n",
    "\n",
    "ravel_metadata = RAVELMetadata(\n",
    "    'tinyllama',\n",
    "    KEPT_ENTITY_SPLITS,\n",
    "    KEPT_ATTR_TO_PROMPT_AND_SPLIT,\n",
    "    KEPT_PROMPT_SPLITS,\n",
    "    WIKI_PROMPT_SPLITS,\n",
    "    ALL_PROMPT_TO_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_label(' Thailand.\\nThe distance from P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Su3jJN1iwK5h",
    "outputId": "5ee46517-fa94-482a-dcf9-f9cf83501a19"
   },
   "outputs": [],
   "source": [
    "#@title Generate the Conetxt TEST/VAL Split\n",
    "\n",
    "# Context Split: All entities are in TRAIN, but all prompts are in test/dev\n",
    "\n",
    "import random\n",
    "\n",
    "from utils.generate_ravel_instance import gen_context_test_split\n",
    "\n",
    "TEST_TYPE = 'context'\n",
    "\n",
    "# Take the first N examples only\n",
    "first_n = 256\n",
    "\n",
    "eval_split_to_raw_example = gen_context_test_split(\n",
    "    ravel_metadata,\n",
    "    extract_label_fn=extract_label,\n",
    "    filter_example_fn=filter_inv_example,\n",
    "    first_n=first_n)\n",
    "eval_split_to_dataset = {\n",
    "    split: Dataset.from_list(eval_split_to_raw_example[split][:first_n], features=FEATURE_TYPES)\n",
    "    for split in eval_split_to_raw_example}\n",
    "\n",
    "# Compute stats.\n",
    "for split in eval_split_to_raw_example:\n",
    "  print('\\nSplit %s:\\nTotal %d examples, kept first %d examples, %d unique input values,  %d unique entities, %d unique output values, %d unique output tokens' % (\n",
    "      repr(split), len(eval_split_to_raw_example[split]), len(eval_split_to_dataset[split]),\n",
    "      len(set([exp[x] for exp in eval_split_to_raw_example[split][:first_n] for x in ['input', 'source_input']])),\n",
    "      len(set([exp[x] for exp in eval_split_to_raw_example[split][:first_n] for x in ['entity', 'source_entity']])),\n",
    "      len(set([exp['inv_label'] for exp in eval_split_to_raw_example[split][:first_n]])),\n",
    "      len(set([tokenizer('0' + exp['inv_label']).input_ids[3] for exp in eval_split_to_raw_example[split][:first_n]]))))\n",
    "  #for i, example in enumerate(eval_split_to_raw_example[split]):\n",
    "  #  print(example)\n",
    "  #  #print(tokenizer(example['input']).input_ids)\n",
    "  #  break\n",
    "  #for k in ('input', 'source_input'):\n",
    "  #  input_ids = tokenizer(example[k])['input_ids']\n",
    "  #  #print(k)\n",
    "  #  #print(input_ids)\n",
    "  #  print(list(zip([(32 - len(input_ids)) + i for i in range(len(input_ids))], tokenizer.batch_decode(input_ids))))\n",
    "for split in ('test', 'val'):\n",
    "  print(f'Split {split}: Total #subsplit={len([k for k in eval_split_to_raw_example if k.endswith(split)])} #Examples={sum(map(len, [v for k, v in eval_split_to_raw_example.items() if k.endswith(split)]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCqiWwopEC2_"
   },
   "outputs": [],
   "source": [
    "# Merge subsplits\n",
    "eval_split_to_raw_example_merged = collections.defaultdict(list)\n",
    "for split in eval_split_to_raw_example:\n",
    "  eval_split_to_raw_example_merged[re.sub(r'-causal|-output|-other', '', split)].extend(eval_split_to_raw_example[split])\n",
    "eval_split_to_raw_example = dict(eval_split_to_raw_example_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHSF9zO1QpLI"
   },
   "outputs": [],
   "source": [
    "output_json_path = os.path.join(DATA_DIR, f'{ravel_metadata.instance}/{ravel_metadata.instance}_{ENTITY_TYPE}_{TEST_TYPE}_test.json')\n",
    "print(output_json_path)\n",
    "json.dump(eval_split_to_raw_example, open(output_json_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cELK5Wck671X",
    "outputId": "3279061c-f90c-4f11-d7de-77331ec2b022"
   },
   "outputs": [],
   "source": [
    "#@title Generate the Entity TEST/VAL Split\n",
    "\n",
    "from utils.generate_ravel_instance import gen_entity_test_split\n",
    "\n",
    "TEST_TYPE = 'entity'\n",
    "\n",
    "# Take the first N examples only\n",
    "first_n = 128\n",
    "\n",
    "eval_split_to_raw_example = gen_entity_test_split(\n",
    "    ravel_metadata,\n",
    "    extract_label_fn=extract_label, filter_example_fn=filter_inv_example,\n",
    "    first_n=first_n)\n",
    "\n",
    "eval_split_to_dataset = {\n",
    "    split: Dataset.from_list(eval_split_to_raw_example[split][:first_n], features=FEATURE_TYPES)\n",
    "    for split in eval_split_to_raw_example}\n",
    "\n",
    "# Stats\n",
    "for split in eval_split_to_raw_example:\n",
    "  print('Split %s: Total %d examples, kept first %d examples, %d unique input values,  %d unique entities, %d unique output values, %d unique output tokens' % (\n",
    "      repr(split), len(eval_split_to_raw_example[split]), len(eval_split_to_dataset[split]),\n",
    "      len(set([exp[x] for exp in eval_split_to_raw_example[split][:first_n] for x in ['input', 'source_input']])),\n",
    "      len(set([exp[x] for exp in eval_split_to_raw_example[split][:first_n] for x in ['entity', 'source_entity']])),\n",
    "      len(set([exp['inv_label'] for exp in eval_split_to_raw_example[split][:first_n]])),\n",
    "      len(set([tokenizer('0' + exp['inv_label']).input_ids[3] for exp in eval_split_to_raw_example[split][:first_n]]))))\n",
    "  for i, example in enumerate(eval_split_to_raw_example[split]):\n",
    "    print(example)\n",
    "    #print(tokenizer(example['input']).input_ids)\n",
    "    break\n",
    "  for k in ('input', 'source_input'):\n",
    "    input_ids = tokenizer(example[k])['input_ids']\n",
    "    #print(k)\n",
    "    #print(input_ids)\n",
    "    print(list(zip([(32 - len(input_ids)) + i for i in range(len(input_ids))], tokenizer.batch_decode(input_ids))))\n",
    "for split in ('test', 'val'):\n",
    "  print(f'Split {split}: Total #subsplit={len([k for k in eval_split_to_raw_example if k.endswith(split)])} #Examples={sum(map(len, [v for k, v in eval_split_to_raw_example.items() if k.endswith(split)]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIui4buzFi5N"
   },
   "outputs": [],
   "source": [
    "# Merge subsplits\n",
    "eval_split_to_raw_example_merged = collections.defaultdict(list)\n",
    "for split in eval_split_to_raw_example:\n",
    "  eval_split_to_raw_example_merged[re.sub(r'-causal|-output|-other', '', split)].extend(eval_split_to_raw_example[split])\n",
    "eval_split_to_raw_example = dict(eval_split_to_raw_example_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45Xe-rvibqeQ"
   },
   "outputs": [],
   "source": [
    "output_json_path = os.path.join(DATA_DIR, f'{ravel_metadata.instance}/{ravel_metadata.instance}_{ENTITY_TYPE}_{TEST_TYPE}_test.json')\n",
    "print(output_json_path)\n",
    "json.dump(eval_split_to_raw_example, open(output_json_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HB1P3ZNziM7c",
    "outputId": "b80cd416-2c23-4d93-b2a1-d10036654b43"
   },
   "outputs": [],
   "source": [
    "#@title Generate train split (for models that use counterfactuals)\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "def gen_train_split(metadata, extract_label_fn, filter_example_fn, first_n=256):\n",
    "  split_to_raw_example = {}\n",
    "  # Group by attributes.\n",
    "  target_split = 'train'\n",
    "  for attr, prompt_to_split in metadata.attr_to_prompt.items():\n",
    "      base_prompt_candiates = [p for p, s in prompt_to_split.items() if s == target_split]\n",
    "      base_task_inputs = [\n",
    "          ((prompt, entity), metadata.prompt_to_output[prompt % entity])\n",
    "          for entity in metadata.get_entities(target_split)\n",
    "          for prompt in random.sample(\n",
    "              base_prompt_candiates, k=min(2, len(base_prompt_candiates)))]\n",
    "      source_task_inputs = [\n",
    "          ((source_prompt, entity), metadata.prompt_to_output[source_prompt % entity])\n",
    "          for source_prompt, (source_attr, source_split) in KEPT_PROMPT_SPLITS.items()\n",
    "          if source_split == target_split and source_attr != 'Other'\n",
    "          for entity in metadata.sample_entities(target_split, k=1)\n",
    "      ]\n",
    "      wiki_source_task_inputs = [\n",
    "          ((source_prompt, entity), metadata.prompt_to_output[source_prompt % entity])\n",
    "          for source_prompt, split_and_arg in metadata.entity_prompt_to_split.items()\n",
    "          if split_and_arg['split'] == target_split\n",
    "          for entity in ([split_and_arg['entity']] if split_and_arg['entity']\n",
    "                         else metadata.sample_entities(target_split, k=1))\n",
    "      ]\n",
    "      source_task_inputs = source_task_inputs + wiki_source_task_inputs\n",
    "      if len(base_task_inputs) < 5 or len(source_task_inputs) < 5:\n",
    "        continue\n",
    "      print(attr, target_split, len(base_task_inputs), len(source_task_inputs), len(wiki_source_task_inputs))\n",
    "      split_to_raw_example[f'{attr}-{target_split}'] = []\n",
    "      for (p, a), v in base_task_inputs:\n",
    "        source_input_candiates = [x for x in source_task_inputs if filter_example_fn(v, metadata.prompt_to_output[p % x[0][1]])]\n",
    "        #print(len(source_input_candiates), v)\n",
    "        split_to_raw_example[f'{attr}-{target_split}'].extend([{\n",
    "          'input': p % a, 'label': extract_label_fn(v),\n",
    "          'source_input': s_p % s_a, 'source_label': extract_label_fn(source_v),\n",
    "          'inv_label': extract_label_fn(metadata.prompt_to_output[p % s_a]),\n",
    "          'split': p, 'source_split': s_p,\n",
    "          'entity': a, 'source_entity': s_a}\n",
    "        for (s_p, s_a), source_v in random.sample(source_input_candiates, k=min(len(source_input_candiates), round(first_n / len(base_task_inputs))))\n",
    "        if filter_example_fn(v, metadata.prompt_to_output[p % s_a]) and re.search('\\w+', source_v)\n",
    "      ])\n",
    "  split_to_raw_example = {k: v for k, v in split_to_raw_example.items() if len(v) > 0}\n",
    "  return split_to_raw_example\n",
    "\n",
    "\n",
    "# Take the first N examples only\n",
    "first_n = 10240\n",
    "\n",
    "split_to_raw_example = gen_train_split(\n",
    "    ravel_metadata,\n",
    "    extract_label_fn=extract_label,\n",
    "    filter_example_fn=filter_inv_example,\n",
    "    first_n=first_n)\n",
    "\n",
    "# Stats\n",
    "for split in split_to_raw_example:\n",
    "  print('Split %s: Total %d examples, kept first %d examples, %d unique input values,  %d unique entities, %d unique output values, %d unique output tokens' % (\n",
    "      repr(split), len(split_to_raw_example[split]), len(split_to_raw_example[split]),\n",
    "      len(set([exp[x] for exp in split_to_raw_example[split][:first_n] for x in ['input', 'source_input']])),\n",
    "      len(set([exp[x] for exp in split_to_raw_example[split][:first_n] for x in ['entity', 'source_entity']])),\n",
    "      len(set([exp['inv_label'] for exp in split_to_raw_example[split][:first_n]])),\n",
    "      len(set([tokenizer('0' + exp['inv_label']).input_ids[3] for exp in split_to_raw_example[split][:first_n]]))))\n",
    "  for i, example in enumerate(split_to_raw_example[split]):\n",
    "    print(example)\n",
    "    #print(tokenizer(example['input']).input_ids)\n",
    "    break\n",
    "  #for k in ('input', 'source_input'):\n",
    "  #  input_ids = tokenizer(example[k])['input_ids']\n",
    "  #  #print(k)\n",
    "  #  #print(input_ids)\n",
    "  #  print(list(zip([(32 - len(input_ids)) + i for i in range(len(input_ids))], tokenizer.batch_decode(input_ids))))\n",
    "for split in ('train',):\n",
    "  print(f'Split {split}: Total #subsplit={len([k for k in split_to_raw_example if k.endswith(split)])} #Examples={sum(map(len, [v for k, v in split_to_raw_example.items() if k.endswith(split)]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-a23pstkqr6U"
   },
   "outputs": [],
   "source": [
    "json_path = os.path.join(DATA_DIR, f'{ravel_metadata.instance}/{ravel_metadata.instance}_{ENTITY_TYPE}_train.json')\n",
    "print(json_path)\n",
    "json.dump(split_to_raw_example, open(json_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yj87A4_OoW7",
    "outputId": "b6042ddc-02ae-4e8e-cf0a-48e8b95cff4c"
   },
   "outputs": [],
   "source": [
    "#@title Postprocess labels\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "# from intervention_utils import extract_label\n",
    "\n",
    "\n",
    "entity_type = 'city'\n",
    "instance =  'tinyllama'\n",
    "version = ''\n",
    "\n",
    "\n",
    "attribute_to_prompts = json.load(open(os.path.join(DATA_DIR + version, 'base', f'ravel_{entity_type}_attribute_to_prompts.json')))\n",
    "\n",
    "\n",
    "json_path = os.path.join(DATA_DIR + version, f'{instance}/{instance}_{entity_type}_context_test.json')\n",
    "split_to_raw_example = json.load(open(json_path, 'r'))\n",
    "print(len(split_to_raw_example))\n",
    "\n",
    "all_labels = set()\n",
    "for split in split_to_raw_example:\n",
    "  for i in range(len(split_to_raw_example[split])):\n",
    "    if split.split('-')[0] in ['Latitude', 'Longitude'] or  split.split('-')[0] in attribute_to_prompts['Latitude'] or split.split('-')[0] in attribute_to_prompts['Longitude']:\n",
    "      # Keep only the integer part.\n",
    "      split_to_raw_example[split][i]['inv_label'] = split_to_raw_example[split][i]['inv_label'].replace('°', '.').split('.')[0]\n",
    "      split_to_raw_example[split][i]['label'] = split_to_raw_example[split][i]['label'].replace('°', '.').split('.')[0]\n",
    "    all_labels.add(split_to_raw_example[split][i]['inv_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCOrt1xqS0L9"
   },
   "outputs": [],
   "source": [
    "json.dump(split_to_raw_example, open(json_path, 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaKW4KTgiOO1",
    "outputId": "dc973865-d7e3-4291-c78b-2cab903f4233"
   },
   "outputs": [],
   "source": [
    "sorted(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7jT94__J6Jf",
    "outputId": "635e8f9e-6286-49d1-a864-b42c0d2c6542"
   },
   "outputs": [],
   "source": [
    "#@title Intervention locations for all possible prompts\n",
    "\n",
    "SPLIT_TO_INV_POSITION = {}\n",
    "\n",
    "all_prompt_templates = {p for p in WIKI_PROMPT_SPLITS}\n",
    "all_prompt_templates.update({v for vs in ALL_ATTR_TO_PROMPTS.values() for v in vs})\n",
    "print(len(all_prompt_templates))\n",
    "\n",
    "for prompt_template in all_prompt_templates:\n",
    "  if prompt_template.count('%s') != 1:\n",
    "    continue\n",
    "  print(prompt_template)\n",
    "  prompt_input = prompt_template.replace('%s', '000000', 1)\n",
    "  input_ids = tokenizer(prompt_input)['input_ids']\n",
    "  toks = tokenizer.batch_decode(input_ids)\n",
    "  for i in range(-1, -len(toks), -1):\n",
    "    if toks[i] == '0' and toks[i - 1] == '0' and toks[i - 2] == '0' and toks[i - 3] == '0':\n",
    "      break\n",
    "  SPLIT_TO_INV_POSITION[prompt_template] = i\n",
    "  print(i, list(zip([(32 - len(input_ids)) + i for i in range(len(input_ids))], toks)))\n",
    "\n",
    "print(min(SPLIT_TO_INV_POSITION.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsjBIBi05vtL"
   },
   "outputs": [],
   "source": [
    "version = ''\n",
    "json.dump(SPLIT_TO_INV_POSITION,\n",
    "          open(os.path.join(DATA_DIR + version, instance, f'{instance}_{entity_type}_prompt_to_entity_position.json'), 'w'),\n",
    "          ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4r6ETYXK0Mhc"
   },
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gemma\n",
    "# layer_idx = 20\n",
    "# submodule = model.model.layers[layer_idx].post_feedforward_layernorm\n",
    "\n",
    "def get_representations_llama(nnsight_model, layer_idx, encoded_input):\n",
    "    submodule = nnsight_model.model.layers[layer_idx]\n",
    "    with torch.no_grad(), nnsight_model.trace(encoded_input, **tracer_kwargs):\n",
    "        output = submodule.output[0].save()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaHAwei3-zA1"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import re\n",
    "import pickle as pkl\n",
    "\n",
    "# from extract_neuron_activations import get_representations_across_layers_llama\n",
    "\n",
    "\n",
    "def extract_ravel_entity_features(entity_to_split, attribute_to_prompt_and_split,\n",
    "                                  layer, output_path, batch_size=128, placeholder='%s'):\n",
    "  print(output_path)\n",
    "  f_out = h5py.File(output_path, \"a\")\n",
    "  # Generate prompts.\n",
    "  splits = {'train': ('train', 'train'),\n",
    "                 'val_entity': ('val', 'train'),\n",
    "                 'val_context': ('train', 'val'),}\n",
    "  for split_name, (entity_split, prompt_split) in splits.items():\n",
    "    for attr, prompt_to_split in attribute_to_prompt_and_split.items():\n",
    "      inputs, entities, templates = zip(*[(p[:p.index(placeholder)] + e, e, p)\n",
    "          for p in prompt_to_split if prompt_to_split[p] == prompt_split\n",
    "          for e in entity_to_split if entity_to_split[e] == entity_split])\n",
    "      all_features = []\n",
    "      for b_i in range(0, len(inputs), batch_size):\n",
    "        input_batch = inputs[b_i:b_i+batch_size]\n",
    "        encoded_input = tokenizer(\n",
    "            input_batch, padding=\"max_length\", max_length=INPUT_MAX_LEN,\n",
    "            return_tensors=\"pt\", truncation=True)\n",
    "        with torch.no_grad():\n",
    "          # outputs = get_representations_across_layers_llama(\n",
    "          #     model.model, encoded_input, layer_index=layer)[f'layer_{layer}-block_output']\n",
    "          outputs = get_representations_llama(nnsight_model, layer, encoded_input)\n",
    "          for i in range(len(input_batch)):\n",
    "            all_features.append(outputs[i:i+1, -1, :].to(torch.float16).cpu().numpy())\n",
    "      print(attr, split_name, np.concatenate(all_features).shape)\n",
    "      f_out[f'{attr}-{split_name}'] = np.concatenate(all_features)\n",
    "      f_out[f'{attr}-{split_name}' + '_input'] = np.void(pkl.dumps(inputs))\n",
    "      f_out[f'{attr}-{split_name}' + '_template'] = np.void(pkl.dumps(templates))\n",
    "      f_out[f'{attr}-{split_name}' + '_entity'] = np.void(pkl.dumps(entities))\n",
    "  f_out.flush()\n",
    "  f_out.close()\n",
    "\n",
    "\n",
    "INPUT_MAX_LEN = 48\n",
    "\n",
    "\n",
    "for layer in [14]:\n",
    "  output_path = os.path.join(DATA_DIR, f'ravel_city_tinyllama_layer{layer}_representation.hdf5')\n",
    "  extract_ravel_entity_features(\n",
    "      KEPT_ENTITY_SPLITS, KEPT_ATTR_TO_PROMPT_AND_SPLIT,\n",
    "      layer, output_path, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
